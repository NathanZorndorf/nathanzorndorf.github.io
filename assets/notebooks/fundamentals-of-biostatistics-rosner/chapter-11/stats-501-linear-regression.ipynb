{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6 - MLR Model Evaluation\n",
    "\n",
    "# Hypothesis Tests for Regression Models\n",
    "\n",
    "3 hypothesis tests for regression models:\n",
    "1. a hypothesis test for testing that all of the slope parameters are 0\n",
    "    - Research question: \"*are any of the predictors related to the dependent variable?*\"\n",
    "$$\\begin{aligned}\n",
    "&H_{0}: \\beta_{1}=\\beta_{2}=\\beta_{3}=0\\\\\n",
    "&H_{A}: \\text { At least one } \\beta_{i} \\neq 0 \\text { (for } \\left.\\mathrm{i}=1,2,3\\right)\n",
    "\\end{aligned}$$<br>\n",
    "2. a hypothesis test for testing that one slope parameter is 0\n",
    "    - Research question: \"*Is a particular predictor $\\beta_{l}$ related to the dependent variable,  controlling for all other predictors?*\"\n",
    "$$\\begin{aligned}\n",
    "&H_{0}: \\beta_{l}=0\\\\\n",
    "&H_{A}: \\beta_{l} \\neq 0\n",
    "\\end{aligned}$$<br>\n",
    "3. a hypothesis test for testing that a subset — more than one, but not all — of the slope parameters are 0    \n",
    "    - Research question: \"*Is a set of predictors related to the dependent variable, controlling for all other predictors?*\"\n",
    "$$\\begin{aligned}\n",
    "&H_{0}: \\beta_{2}=\\beta_{3}=0\\\\\n",
    "&H_{A}: \\text { At least one } \\beta_{i} \\neq 0 \\text { (for } \\left.\\mathrm{i}=2,3\\right)\n",
    "\\end{aligned}$$<br>\n",
    "\n",
    "An **F-Test** will allow you to test all three hypotheses - by providing a test statistics to test for the significance of one, a subset, or all of the coefficients of a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: The General F-Test\n",
    "\n",
    "From: https://online.stat.psu.edu/stat501/lesson/6/6.2\n",
    "\n",
    "Generally, an **F-test** tests whether a simpler **\"reduced\"** model (fewer coefficients) a better fit to the data than a **\"full\" (or \"unrestricted\")** model (with more coefficients)? \n",
    "\n",
    "**Hypotheses for a General F-Test**:\n",
    "- H0: Reduced model represents the data better\n",
    "- Ha: Full model represents the data better\n",
    "\n",
    "**Statistic**:<br>\n",
    "$F=\\left(\\frac{S S E(R)-S S E(F)}{d f_{R}-d f_{F}}\\right) \\div\\left(\\frac{S S E(F)}{d f_{F}}\\right)$<br>\n",
    "\n",
    "- The associated p-value is calculated by inputting the F-statistic into the appropriate CDF of the F distribution (with parameters df<sub>numerator</sub> and df<sub>denominator</sub>) and subtracting the result from 1.\n",
    "    - df<sub>numerator</sub> = $df_{R} - df_{F}$\n",
    "    - df<sub>denominator</sub> = $df_{F}$\n",
    "\n",
    "- \"Sum of Squares\" = \"Sum of Squared Error\" = \"Error Sum of Squares\" = $SSE = \\sum(\\text { observed }-\\text { fitted })^{2}$<br>\n",
    "\n",
    "- $SSE(F)=\\sum\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$, where F = \"Full Mode\", for example: $y_{i} = (\\beta_{0} + \\beta_{1}x_{i1}) + \\epsilon_{i}$<br>\n",
    "\n",
    "- $\\operatorname{SSE}(R)=\\sum\\left(y_{i}-\\bar{y}\\right)^{2}$, where R = \"Reduced Model\", for example $ y_{i} = \\beta_{0} + \\epsilon_{i}$<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test for significance of any regression coefficient (\"Overall Model Test\")\n",
    "\n",
    "*(according to my understanding) we're trying to answer the question: \"Is there really this relationship in the population, or is this regression line, with it's non-zero coefficients, just the result of variability in the sample?*\n",
    "\n",
    "**Hypotheses for Overall Model F-Test**:\n",
    "- H0: all $\\beta_{l} = 0$\n",
    "- Ha: at least one $\\beta_{l} \\neq 0$\n",
    "\n",
    "## 2. Testing an individual regression coefficient\n",
    "\n",
    "*Note: that these procedures test specifically for the relevance of a single coefficient in the context of a multiple linear regression model including the other coefficients. It does **not** test for the significance of the relationship between the response y and a predictor $\\beta_{l}$ alone.*\n",
    "\n",
    "use a **t test** to test whether a regression coefficient is == 0 or != 0\n",
    "\n",
    "**Hypotheses**:\n",
    "- H0: βl = 0, All Other βj ≠ 0 (reduced model)\n",
    "- Ha: βl ≠ 0, All Other βj ≠ 0 (full model)\n",
    "\n",
    "Or use an equivalent **F-test** to test whether a regression coefficient is == 0 or !=0\n",
    "\n",
    "**Hypotheses**:\n",
    "- H0: βl = 0, All Other βj ≠ 0 (reduced model)\n",
    "- Ha: βl ≠ 0, All Other βj ≠ 0 (full model)\n",
    "\n",
    "## 3. Testing a subset of regression coefficients\n",
    "\n",
    "**Hypotheses**:<br>\n",
    "$\\begin{aligned}\n",
    "&H_{0}: \\beta_{2}=\\beta_{3}=0\\\\\n",
    "&H_{A}: \\text { At least one } \\beta_{i} \\neq 0 \\text { (for } \\left.\\mathrm{i}=2,3\\right)\n",
    "\\end{aligned}$\n",
    "\n",
    "To test whether a subset — more than one, but not all — of the slope parameters are 0, there are two equivalent ways to calculate the F-statistic:\n",
    "1. Use the **general linear F-test** formula by fitting the full model to find SSE(F) and fitting the reduced model to find SSE(R).\n",
    "2. Alternatively, use the **partial F-test formula** (see https://online.stat.psu.edu/stat501/lesson/6/6.4#paragraph--679 for more info) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating a research question in a statistical procedure\n",
    "\n",
    "the need for being able to \"translate\" a research question into a statistical procedure. Often, the procedure involves four steps, namely:\n",
    "- formulating a multiple regression model\n",
    "- determining how the model helps answer the research question\n",
    "- checking the model\n",
    "- and performing a hypothesis test (or calculating a confidence interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness of Fit / Model Evaluation\n",
    "\n",
    "**Externally Studentized residual**: *i*th data point not used in the estimation of regression parameters. Used in the case of outliers to remove their effect from the regression. \n",
    "\n",
    "**Internally Studentized residual**: because the ith data point was used in estimating the regression parameters.\n",
    "\n",
    "**R<sup>2</sup>** (i.e.  the Coefficient of Determination): it is the proportion of the variance in the outcome variable that can be accounted for by the predictor. \n",
    "- 1- R<sup>2</sup> quantifies the amount of variance left over in the independent variable after the model is taken into account\n",
    "    - R<sup>2</sup> quantifies the reduction in variance after the model is taken into account.  \n",
    "\n",
    "**Adjusted R<sup>2</sup>**: Adding more predictors to the model will always increase the R<sup>2</sup>, so the adjusted R<sup>2</sup> only increases when a new predictor actually increases the performance of the model. \n",
    "- $\\text{Adjusted } R^{2}=1-\\left(\\frac{n-1}{n-p}\\right)\\left(1-R^{2}\\right)$\n",
    "- This is useful to use when comparing different multiple linear regression models, as the number of terms in the model won't inflate the adjusted R<sup>2</sup> like it will for the un-adjusted R<sup>2</sup>. However, the adjusted R<sup>2</sup> does not have the same interpretation as the un-adjusted R<sup>2</sup> (proportion of the variance explained in the dependent variable by the predictors).\n",
    "- Also useful for determining which coefficients are additive to the model, since the adjusted R<sup>2</sup> won't increase unless a predictor actually increases the explaine variance in the independent variable. \n",
    "\n",
    "**Partial R<sup>2</sup>** (i.e.  the Coefficient of Partial Determination): The proportion of the variance in model B that is not explained by model A, i.e. how much more variance can be accounted for by including the additional predictors in model B (with respect to model A).\n",
    "\\begin{aligned}\n",
    "R_{y, B \\mid A}^{2} &=\\frac{\\operatorname{SSR}(B \\mid A)}{\\operatorname{SSE}(A)} \\\\\n",
    "&=\\frac{\\operatorname{SSE}(A)-\\operatorname{SSE}(A, B)}{\\operatorname{SSE}(A)}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 7 - MLR Estimation, Prediction & Model Assumptions\n",
    "\n",
    "## 7.3 Model Assumptions\n",
    "\n",
    "## 7.4 Assessing the Model Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
